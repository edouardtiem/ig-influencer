# Perplexity Search Results

> Generated: 2026-01-31T11:33:48.743Z
> Model: sonar-pro
> Duration: 6.6s

---

## Problem

Z-Image Full model ComfyUI settings 2025 2026 - NOT Turbo - what steps CFG sampler scheduler for Z-Image Full bf16 - how many inference steps needed - correct workflow parameters


---

## Search Results

### Z-Image Full/Base Model ComfyUI Settings (bf16, Non-Turbo)

For **Z-Image Full/Base** (bf16 variant like `z_image_base_bf16.safetensors`), use these optimized settings in ComfyUI workflows for high-fidelity, photorealistic generation prioritizing quality over speed (unlike Turbo).[1][4]

#### Core Workflow Steps
1. **Load Models**:
   - **UNet**: `z_image_base_bf16.safetensors` (or equivalent Full/Base bf16 model) via `UNETLoader` node.[1]
   - **Text Encoder**: `qwen_3_4b.safetensors` (Qwen 3 4B) via `CLIPLoader` for strong prompt adherence and text rendering.[1][2]
   - **VAE**: `ae.safetensors` via `VAELoader` for decoding.[1][2]

2. **Set Latent Image**:
   - Use `EmptySD3LatentImage` node.
   - Dimensions: Multiples of 64px (e.g., **1280x720** for 16:9).[1][2]
   - Adjust width/height for composition; wider for landscapes.

3. **Prompts**:
   - **Positive**: Clear, detailed prompts; keep short for bilingual/text rendering.
   - **Negative**: Brief (e.g., "blur, extra limbs, messy typography") to avoid overconstraining.[1]

4. **Sampler Configuration** (tuned for Z-Image Base):
   | Parameter     | Recommended Value          | Notes |
   |---------------|----------------------------|-------|
   | **Sampler**  | Euler (default for Z-Image workflows) | Reliable for fidelity; test ancestral if needed.[1] |
   | **Scheduler**| Simple or Normal          | Matches Base model's diffusion needs; avoids Turbo's low-step optimizations.[1] |
   | **CFG**      | **4.0 - 6.0**              | Start at 5.0; lower (e.g., 4.5) if oversaturation/halos occur.[1] |
   | **Steps**    | **20-30**                  | 25 optimal for quality; Turbo uses 8, but Base needs more for detail/texture realism.[1][2][4] |
   | **Denoise**  | 1.0 (text-to-image)        | Full denoising for new images.[1] |

5. **Run & Refine**:
   - Fix **seed** for comparisons.
   - Generate, then upscale/edit if needed (Base excels here).[1]
   - VRAM: 12-16GB+ recommended for 1024x1024+ at bf16; use --bf16 flag if supported.[2][6]

#### Full Workflow JSON
Download pre-wired workflows from sources like runcomfy.com; swap UNet to Base bf16.[1] Example node chain: Models → CLIPTextEncode (pos/neg) → KSampler → VAE Decode → Save Image.

**Pro Tip**: Base outperforms Turbo in realism, prompt adherence, and textures (e.g., shiny skin, better people prompts).[4] Test with 25 steps/CFG 5.0/Euler/Simple for 2025-2026 benchmarks. If VRAM-limited, quantize to GGUF via ComfyUI-GGUF.[5]

---

## Citations

1. https://www.runcomfy.com/comfyui-workflows/z-image-workflow-in-comfyui-high-fidelity-image-generation
2. https://www.nextdiffusion.ai/tutorials/z-image-turbo-fast-uncensored-image-generation-comfyui
3. https://www.youtube.com/watch?v=P2Xw72lvEyo
4. https://www.youtube.com/watch?v=w0ml5EKB2q0
5. https://dev.to/gary_yan_86eb77d35e0070f5/amazing-z-image-workflow-v30-complete-guide-to-enhanced-comfyui-image-generation-1j65
6. https://stable-diffusion-art.com/z-image/

---

## Related Questions

- How do I configure the CFG sampler for Z-Image Full in ComfyUI
- What are the recommended scheduler settings for Z-Image Full
- How many inference steps are typically needed for Z-Image Full
- What are the key differences between Z-Image Full and Z-Image Turbo
- Can I use Z-Image Full with bilingual prompts effectively

---

## Suggested Next Steps

Based on the search results above:

1. Review the most relevant citations for deeper understanding
2. Try the suggested solutions in order of relevance
3. If the problem persists, refine the search with more specific details

---

*Search powered by Perplexity Sonar Pro*

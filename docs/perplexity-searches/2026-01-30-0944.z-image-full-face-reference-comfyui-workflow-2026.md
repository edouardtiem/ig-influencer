# Perplexity Search Results

> Generated: 2026-01-30T08:44:33.139Z
> Model: sonar-pro
> Duration: 12.5s

---

## Problem

Z-Image Full face reference ComfyUI workflow 2026 - how to use reference image with Z-Image for face identity? IP-Adapter Z-Image compatibility? Z-Image image conditioning face transfer tutorial


---

## Search Results

To use a **reference image for face identity** in ComfyUI with **Z-Image** (a fast diffusion model like Z-Image Turbo), leverage **IP-Adapter** for image conditioning and face transfer. IP-Adapter is compatible with Z-Image after code modifications, enabling lightweight face reference without full fine-tuning.[1][2][3]

### Key Compatibility Notes
- **IP-Adapter Z-Image Support**: Research shows SD3 IP-Adapters work with Z-Image Turbo via ComfyUI code tweaks (e.g., adapter integration patches shared by @DragonDiffusionbyBoyo). It's reusable across custom models like Z-Image and combines with ControlNet for structure/face control.[1][2][5]
- Z-Image LoRA trainers exist for custom face adapters, but IP-Adapter is lighter (~22M params) and excels at face/style transfer from reference images.[3][7]

### Step-by-Step ComfyUI Workflow for Face Identity Transfer (2026 Setup)
1. **Install Dependencies**:
   - Update ComfyUI to latest (supports IP-Adapter nodes via ComfyUI-IPAdapter_plus or similar custom nodes).
   - Download Z-Image model (e.g., Turbo variant) and IP-Adapter weights (SD3-compatible) from Hugging Face/Tencent-AILab repo.[2][3]
   - Apply Z-Image IP-Adapter patch: Edit ComfyUI nodes per GitHub issue #8743 (merge SD3 adapter code into Z-Image loader).[2]

2. **Load Models**:
   - **Z-Image Checkpoint**: Use `Load Checkpoint` node for Z-Image base.
   - **IP-Adapter Model**: Load via `IPAdapter Unified Loader` (select SD3/face variant for identity strength).
   - **CLIP Vision**: Load CLIP-ViT-H or OpenCLIP for reference image encoding.[1][3]

3. **Prepare Reference Image (Full Face)**:
   - Input a **square, high-res face photo** (resize to 224x224 if non-square to avoid cropping loss).[3]
   - Node: `Load Image` → `IPAdapter Preprocessor` (set `weight_type: style_faceID` for face focus).

4. **Build Conditioning Pipeline**:
   ```
   [Text Prompt] → CLIP Text Encode (positive: "portrait of [description], high detail face")
                  ↓
   [Reference Face Image] → IPAdapter Encode → IPAdapter Apply (strength: 0.8-1.2 for identity)
                  ↓ (concat with text embeds via decoupled cross-attention)[1]
   [Merged Conditioning] → KSampler (Z-Image model, steps: 8-20, CFG: 3-5)
   ```
   - **Face Transfer Tip**: Boost `ipadapter_weight` (0.7-1.0) for identity; combine with FaceID models if available. Use `num_images_per_prompt=1`.[1][4]
   - Add **ControlNet** (e.g., face pose/depth) for better alignment: IP-Adapter is fully compatible.[1][5]

5. **VAE Decode & Output**:
   - `VAE Decode` → `Save Image`.
   - For img2img face swap: Add `VAE Encode` from target image latent.[4][5]

### Example Node Graph (JSON Snippet for ComfyUI)
```json
{
  "nodes": [
    {"class_type": "IPAdapterUnifiedLoader", "inputs": {"ipadapter_file": "ip-adapter_sd3_face.bin"}},
    {"class_type": "IPAdapterApply", "inputs": {"ipadapter": [...], "image": [ref_face], "weight": 1.0, "weight_type": "style_faceID"}},
    {"class_type": "KSampler", "inputs": {"model": [zimage], "positive": [merged_cond], "negative": [...], "latent_image": [empty], "steps": 12}}
  ]
}
```
Test with low steps for Turbo speed; refine weight for **precise face identity** (stronger = closer match).[1][2]

### Limitations & Tips (2026)
- **Non-Square Faces**: Resize reference to avoid info loss.[3]
- **Quality**: Outperforms simple adapters via decoupled cross-attention; better than ControlNet Reference-only for faces.[1]
- No official 2026 Z-Image IP-Adapter release in results—use community patches.[2] For tutorials, check ComfyUI IP-Adapter vids (adapt for Z-Image).[6]

This yields faithful face transfers; iterate strengths for best results.[1][4][5]

---

## Citations

1. https://ar5iv.labs.arxiv.org/html/2308.06721
2. https://github.com/invoke-ai/InvokeAI/issues/8743
3. https://github.com/tencent-ailab/IP-Adapter
4. https://www.mercity.ai/blog-post/understanding-and-training-ip-adapters-for-diffusion-models
5. https://ip-adapter.github.io
6. https://www.youtube.com/watch?v=HE9aC8hp3VQ
7. https://wavespeed.ai/models/wavespeed-ai/z-image/base-lora-trainer

---

## Related Questions

- How do I integrate IP-Adapter with Z-Image for face identity
- What are the steps to modify the ComfyUI code for Z-Image compatibility
- Can IP-Adapter handle non-square images effectively
- How does the decoupled cross-attention strategy improve image quality
- What are the benefits of using IP-Adapter over fine-tuning models

---

## Suggested Next Steps

Based on the search results above:

1. Review the most relevant citations for deeper understanding
2. Try the suggested solutions in order of relevance
3. If the problem persists, refine the search with more specific details

---

*Search powered by Perplexity Sonar Pro*

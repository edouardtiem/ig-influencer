# Perplexity Search Results

> Generated: 2026-01-23T15:08:22.991Z
> Model: sonar-pro
> Duration: 13.0s

---

## Problem

Qwen2.5-VL Image Edit ComfyUI setup workflow 2025 2026 - how to use Qwen image editing model in ComfyUI custom nodes installation


---

## Search Results

To set up and use **Qwen2.5-VL-based image editing models** (like Qwen-Image-Edit-2512 or Qwen-Image-Layered) in ComfyUI, install the dedicated **ComfyUI-QwenImageWanBridge** custom node for editing workflows, or use Unsloth GGUF with ComfyUI-GGUF for quantized diffusion-based editing. These support 2025-2026 updates with automatic model downloads from Hugging Face.[6][2][7]

### Step-by-Step Installation (ComfyUI-QwenImageWanBridge for Qwen2.5-VL Image Editing)
1. **Update ComfyUI**: Ensure ComfyUI is on the latest version (2025+ compatible). Run `git pull` in your ComfyUI root or use the desktop app updater.[5][9]
2. **Install the Node**:
   ```
   cd ComfyUI/custom_nodes
   git clone https://github.com/[repo-for-QwenImageWanBridge]  # Check RunComfy for exact repo link[6]
   cd ComfyUI-QwenImageWanBridge  # Or equivalent name
   pip install -r requirements.txt  # Includes transformers >=4.49.0[3][6]
   ```
3. **Restart ComfyUI** and search for **QwenImageWanBridge** nodes in the node menu (under image editing or VLM categories).[6]
4. **Download Models Automatically**: Nodes like DownloadAndLoadQwen2_5_VLModel fetch Qwen2.5-VL to `ComfyUI/models/VLM` or `ComfyUI/models/unet` (e.g., `Qwen/Qwen2.5-VL-7B-Instruct`, `unsloth/Qwen-Image-Edit-2512-GGUF`). Use 4-bit/8-bit quantization for VRAM efficiency (13+ GB recommended).[1][2][3]

### Alternative: Unsloth GGUF Setup for Qwen-Image-Edit (CPU/GPU, No High-End GPU Needed)
For diffusion-based editing (text-guided inpainting, multi-reference):
```
mkdir comfy_ggufs && cd comfy_ggufs
python -m venv .venv && source .venv/bin/activate  # Or .venv\Scripts\activate on Windows
git clone https://github.com/Comfy-Org/ComfyUI.git && cd ComfyUI
pip install -r requirements.txt
cd custom_nodes && git clone https://github.com/city96/ComfyUI-GGUF
cd ComfyUI-GGUF && pip install -r requirements.txt && cd ../..
```
- Place GGUF models: `qwen-image-edit-2511-Q4_K_M.gguf` (UNET, 13.1 GB), `Qwen2.5-VL-7B-Instruct-UD-Q4_K_XL.gguf` (CLIP), `qwen_image_vae.safetensors` (VAE) in `ComfyUI/models/unet`, `/clip`, `/vae`.[2]
- Run: `python main.py --cpu` (slow) or with GPU.[2]

### Basic Image Editing Workflow (Load & Run)
1. **Add Nodes** (Drag from menu or load JSON workflow):
   - **QwenImage Loader** or **Unet Loader (GGUF)**: Select `qwen-image-edit-2512-Q4_K_M.gguf` or FP8 variant (40-series GPU).[2][1]
   - **CLIP Loader**: `Qwen2.5-VL-7B-Instruct` (vision tower for semantic control).[2][6]
   - **Load Image**: Input reference image(s) for editing (supports multi-ref for layered edits).[2][7]
   - **Prompt Node**: Use anchors like "edit **image 1** to add [description]" for dual-path control (Qwen2.5-VL semantics + VAE appearance).[4][2]
   - **Sampler**: Steps 20-30, CFG 7-9, shift 12-13 for sharpness. Enable "keep_model_loaded" for speed.[1][2]
2. **Connect & Queue Prompt**: Image → VAE Encode → UNET (with prompt) → VAE Decode → Save Image.[2][9]
3. **Tips**:
   - **VRAM**: 4-bit GGUF for <16GB; FP16/FP8 for high-end.[1][2]
   - **Advanced**: Use QwenVL (Advanced) node for temp/top_p/beam search in hybrid VLM+edit flows.[1]
   - **Workflow JSON**: Download `unsloth_qwen_image_edit_2511.json` or native ComfyUI templates for Qwen-Image-Edit.[2][9]
   - Test: "Make **image 1** photorealistic with [change]" – avoids "3D render" for realism.[2]

For video/sequence edits, use QwenVL nodes with frame inputs.[1] If errors (e.g., FP8 incompatibility), fallback to 4-bit.[1] Check GitHub issues for 2026 patches.[1][2]

---

## Citations

1. https://github.com/1038lab/ComfyUI-QwenVL
2. https://unsloth.ai/docs/models/qwen-image-2512
3. https://comfy.icu/extension/MakkiShizu__ComfyUI-Qwen2_5-VL
4. https://dev.to/czmilo/2025-latest-complete-guide-to-qwen-image-edit-image-editing-model-2kd5
5. https://www.youtube.com/watch?v=5bXecNcN0X8
6. https://www.runcomfy.com/comfyui-nodes/ComfyUI-QwenImageWanBridge
7. https://z-image.ai/blog/qwen-image-layered-comfyui-workflow-2026
8. https://www.youtube.com/watch?v=XFVUTKFnSaY
9. https://docs.comfy.org/tutorials/image/qwen/qwen-image-edit

---

## Related Questions

- How do I integrate Qwen2.5-VL with ComfyUI for image editing
- What are the key differences between Qwen2.5-VL and Qwen3-VL models
- Can I use Qwen2.5-VL for video editing in ComfyUI
- How do I optimize Qwen2.5-VL performance in ComfyUI
- Are there any specific hardware requirements for running Qwen2.5-VL in ComfyUI

---

## Suggested Next Steps

Based on the search results above:

1. Review the most relevant citations for deeper understanding
2. Try the suggested solutions in order of relevance
3. If the problem persists, refine the search with more specific details

---

*Search powered by Perplexity Sonar Pro*

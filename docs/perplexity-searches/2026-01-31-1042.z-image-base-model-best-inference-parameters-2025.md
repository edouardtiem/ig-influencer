# Perplexity Search Results

> Generated: 2026-01-31T09:42:52.949Z
> Model: sonar-pro
> Duration: 8.0s

---

## Problem

Z-Image Base model best inference parameters 2025 2026 - optimal CFG scale, steps, sampler for LoRA character generation - z-image full vs turbo settings comparison


---

## Search Results

### Z-Image Base Optimal Inference Parameters (2026)

**Z-Image Base**, the 6B-parameter foundation model (now released as Z-Image-Omni-Base in some contexts), prioritizes maximum fidelity over speed, requiring higher step counts (20-50+) compared to Turbo's distilled 8-step inference.[1][3][7] For **LoRA character generation**, use **CFG scale 7-9**, **40-50 steps**, and multi-step samplers like **DPM++ 2M SDE** or **res_2s** with **SGM Uniform scheduler** for optimal detail in faces, textures, and clothingâ€”yielding stable gradients and better convergence during fine-tuning.[1][6]

#### Full vs Turbo Settings Comparison
| Parameter          | Z-Image Base (Full)                          | Z-Image Turbo (Distilled)                  |
|--------------------|----------------------------------------------|--------------------------------------------|
| **Steps**         | 20-50+ for max fidelity; 40% slower but richer details[1] | 5-8 NFEs (e.g., Euler + beta scheduler)[1][3][4] |
| **CFG Scale**     | 7-9 (full CFG support for precise control)[6] | 4-7 (lower for speed, still effective)[1] |
| **Sampler**       | DPM++ 2M SDE, res_2s, SGM Uniform (quality-focused)[1] | Euler/beta (fast), simple/bong_tangent, DPM++ 2M SDE (quality boost)[1] |
| **LoRA Suitability** | Ideal: undistilled for stable training (4k steps, LR 1e-4 to 5e-4, rank 64)[1] | Practical: already viable on 16GB VRAM, community adapters available[1] |
| **VRAM/ Speed**   | 16GB+; longer gen time[1][3]                | Sub-second on H800, fits 16GB consumer GPUs[3][4] |
| **Strengths**     | Higher detail, fine-tuning base[1][7]        | Photorealism, bilingual text, speed[1][3][4] |

#### Step-by-Step Inference Optimization for LoRA Character Gen (Base)
1. **Load Model**: Use DiffSynth-Studio or ComfyUI with FP16 (avoid FP8 for quality loss).[2][8]
   ```python
   from diffusers import DiffusionPipeline
   pipe = DiffusionPipeline.from_pretrained("Tongyi-MAI/Z-Image-Base", torch_dtype=torch.float16)
   pipe.enable_model_cpu_offload()  # For VRAM limits
   pipe.transformer.compile()  # Accelerate (first run slower)
   ```
2. **Prompt Setup**: "Young Chinese woman in red Hanfu, intricate embroidery" + LoRA trigger (e.g., `<lora:character:1>`). Enable prompt enhancer for reasoning.[4][6]
3. **Params**:
   - Steps: 40-50
   - CFG: 8 (tune 7-9 for adherence)
   - Sampler: "dpmpp_2m_sde" + "sgm_uniform"
   - Resolution: 1024x1024
   - Seed: Fixed for reproducibility
4. **Generate**:
   ```python
   image = pipe(prompt, num_inference_steps=45, guidance_scale=8.0, scheduler="SGMUniformScheduler").images[0]
   ```
5. **LoRA Training Tips**: 4000 steps, batch 1-2, rank 64 on Base for consistency (Turbo works but less ideal).[1]
6. **Test & Iterate**: Compare outputs; Base excels in high-freq details (skin, embroidery) post-DMDR updates.[1][4]

Base outperforms Turbo in raw quality for custom LoRAs but trades speed; use Turbo for rapid prototyping.[1][5] Community tools like Ostris AI and Cache-DiT boost both (up to 4x speedup).[1][4]

---

## Citations

1. https://pxz.ai/blog/z-image-turbo-vs-base
2. https://github.com/modelscope/DiffSynth-Studio/blob/main/docs/en/Model_Details/Z-Image.md
3. https://civitai.com/models/2342797/z-image-base
4. https://github.com/Tongyi-MAI/Z-Image
5. https://www.digitalocean.com/community/tutorials/image-generation-model-review
6. https://wavespeed.ai/models/wavespeed-ai/z-image/base
7. https://z-image.me/en/resources
8. https://stable-diffusion-art.com/z-image/

---

## Related Questions

- What are the key differences between Z-Image Base and Turbo
- How does the S3-DiT architecture improve parameter efficiency in Z-Image
- What are the best practices for fine-tuning Z-Image Base
- How does DMDR enhance the quality of Z-Image Turbo
- What are the recommended inference steps for Z-Image Turbo

---

## Suggested Next Steps

Based on the search results above:

1. Review the most relevant citations for deeper understanding
2. Try the suggested solutions in order of relevance
3. If the problem persists, refine the search with more specific details

---

*Search powered by Perplexity Sonar Pro*

# Perplexity Search Results

> Generated: 2026-01-31T10:55:47.496Z
> Model: sonar-pro
> Duration: 10.2s

---

## Problem

Vast.ai ComfyUI setup 2025 2026 - best docker image for RTX GPU pytorch cuda compatibility - how to run ComfyUI on vast.ai correctly working setup guide


---

## Search Results

### Best Docker Image for Vast.ai ComfyUI (RTX GPU, PyTorch CUDA Compatibility, 2025-2026)

Use Vast.ai's **official "ComfyUI" template**—it's pre-configured with **PyTorch**, **CUDA**, and RTX GPU drivers for seamless compatibility (e.g., RTX 3090/4090/5090 with ≥24GB VRAM recommended for workflows).[1][3][4] This Docker-based image includes Jupyter, SSH, and ComfyUI out-of-the-box, avoiding manual CUDA/PyTorch installs. No custom Docker needed; it's optimized for Vast.ai's RTX fleet and handles CUDA 12.x+ for 2026 stability.[1][2]

### Step-by-Step Setup Guide (Verified Working on Vast.ai, 2026)

1. **Rent GPU Instance**:
   - Log into Vast.ai → Search RTX GPUs (e.g., RTX 4090/5090, ≥24GB VRAM, low $/hr + $/TB bandwidth).
   - Filter: On-demand, ≥200GB storage (100GB min, 300GB+ for models/videos).[1][3]
   - Click **Change Template** → Search "ComfyUI" → Select **official ComfyUI template** (includes CUDA toolkit, PyTorch, ComfyUI).[1][3][4]
   - Set storage (can't resize later), then **Rent**.

2. **Launch & Sanity Check** (1-3 min boot):
   - Go to **Instances** → Click **OPEN** (blue button).
   - Launch **Jupyter Terminal** → Run checks:
     ```
     nvidia-smi  # Verify RTX GPU + CUDA (e.g., 12.4+)
     free -h     # RAM
     df -h /workspace  # Disk
     ls -la /workspace/ComfyUI  # Confirm structure
     ```
   - Launch **ComfyUI** app → UI loads at `http://instance-ip:8188` (refresh if slow; wait 60-90s).[1][2][3]

3. **Install Models & Custom Nodes** (Pick One Method):
   | Method | Steps | Pros |
   |--------|-------|------|
   | **GUI (ComfyUI Manager)** | ComfyUI → **Manager** → Install "ComfyUI Model Downloader" → Pull from HF/CivitAI (auto-sorts to `/workspace/ComfyUI/models/` → checkpoints/LoRAs/VAE). Press **R** to reload.[1] | Beginner-friendly, no CLI. |
   | **One-Liner Script (Fastest, Recommended)** | Go to https://promptingpixels.com/deploy → Select Vast.ai → Pick models (HF/CivitAI), custom nodes → Copy script. Paste in Jupyter Terminal → Run. Auto-installs everything correctly.[1][2][9] | 2026-optimized, handles tokens (add HF_TOKEN/CIVITAI_TOKEN).[2][4] |
   | **Manual Download** | SSH/Jupyter: `wget https://huggingface.co/model/ckpt -O /workspace/ComfyUI/models/checkpoints/model.safetensors` → Refresh ComfyUI.[3][4] | Full control. |

4. **Generate & Download**:
   - Build workflow in ComfyUI → **Queue Prompt**.
   - Outputs in `/workspace/ComfyUI/output/` → Use Vast.ai portal **File Browser** → Zip/download.[1][3]
   - Stop via **Destroy** to avoid idle costs (~$0.10-0.50/hr).[3]

### Troubleshooting (RTX/CUDA Issues)
- **CUDA mismatch**: Official template auto-matches host RTX CUDA; `nvidia-smi` confirms. Restart instance if needed.[1]
- **UI won't load**: Wait 90s, refresh, check firewall/instance status.[1]
- **Disk full**: Download outputs → Recreate with more storage.[1]
- **Models missing**: Verify paths; use script for auto-placement.[2][4]
- **Video gen**: Same setup; add ControlNet models for RTX efficiency.[4]

This setup is production-ready for 2026, scales to serverless via Vast.ai templates, and costs ~$0.20-1/hr on RTX GPUs.[1][3][7] For API/batch, expose via Vast.ai proxy.[1]

---

## Citations

1. https://dev.to/promptingpixels/spin-up-comfyui-on-vastai-without-surprises-a-practical-developer-first-guide-2k16
2. https://www.youtube.com/watch?v=qL4uqeNC66E
3. https://www.youtube.com/watch?v=xEb1G6_XhcA
4. https://docs.vast.ai/video-generation
5. https://vast.ai/article/getting-started-with-comfy-UI
6. https://www.youtube.com/watch?v=txgJ6d0WEDM
7. https://vast.ai/article/comfyui-serverless
8. https://comfyui-wiki.com/en/install
9. https://promptingpixels.com/tutorial/comfyui-install-cloud-gpus

---

## Related Questions

- What are the best practices for optimizing ComfyUI performance on Vast.ai
- How can I automate the setup of ComfyUI on Vast.ai
- Are there any common issues when running ComfyUI on Vast.ai and how can they be resolved
- What are the cost implications of using different GPU options on Vast.ai for ComfyUI
- How can I integrate custom nodes with ComfyUI on Vast.ai

---

## Suggested Next Steps

Based on the search results above:

1. Review the most relevant citations for deeper understanding
2. Try the suggested solutions in order of relevance
3. If the problem persists, refine the search with more specific details

---

*Search powered by Perplexity Sonar Pro*

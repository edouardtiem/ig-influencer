# üìù SESSION ‚Äî Elena LoRA RunPod Setup & Training

**Date** : 20 janvier 2026  
**Dur√©e** : ~1h  
**Status** : üöß En cours ‚Äî Dataset pr√©par√©, pr√™t pour training RunPod

---

## üéØ Objectif

Lancer un training LoRA haute qualit√© sur RunPod avec 35 images Elena pour am√©liorer la consistance du visage (actuellement ~10-15% avec 10 images locales).

---

## ‚úÖ Ce qui a √©t√© fait cette session

### 1. **üîç Recherche Best Practices LoRA SDXL 2025-2026**

**Param√®tres optimaux identifi√©s :**

| Param√®tre | Valeur Optimale | Justification |
|-----------|----------------|---------------|
| **Rank/Dim** | 32 | Sweet spot pour character LoRA |
| **Alpha** | 16 (dim/2) | Training stable |
| **UNet LR** | 2e-4 | Plus agressif pour meilleur apprentissage |
| **Text Encoder LR** | 5e-5 | **CRUCIAL** pour reconnaissance trigger word |
| **Total Steps** | 1500-3000 | Community recommande pour character |
| **train_text_encoder** | ‚úÖ Oui | Active apprentissage visage via prompt |
| **min_snr_gamma** | 5 | Am√©liore nettet√© visage |
| **keep_tokens** | 1 | Garde "elena" en premier toujours |
| **Gradient Accum** | 2 | Effective batch size = 2 |

**Sources :**
- Reddit r/StableDiffusion (2025-2026 discussions)
- Apatero.com Kohya training guides
- PropelRC LoRA settings explained

### 2. **üîß Scripts RunPod Cr√©√©s**

**Fichiers cr√©√©s :**

1. **`app/scripts/runpod-lora-training.mjs`**
   - Gestion pods RunPod (create/status/stop/resume/terminate)
   - Configuration optimis√©e pour RTX 4090
   - Test connexion API ‚úÖ (API key valid√©e)

2. **`app/scripts/prepare-lora-dataset-cloud.mjs`**
   - Download 35 images depuis Cloudinary
   - Resize automatique 1024x1024
   - G√©n√©ration captions optimis√©es (trigger word + features)

3. **`runpod-training-script.sh`**
   - Script bash √† ex√©cuter sur le pod
   - Installation kohya_ss automatique
   - Training avec param√®tres optimaux

**Configuration training :**
```bash
RESOLUTION="1024,1024"
BATCH_SIZE=1
GRAD_ACCUM=2
MAX_TRAIN_STEPS=2100        # 35 images √ó 10 repeats √ó 6 epochs
UNET_LR="2e-4"
TEXT_ENCODER_LR="5e-5"
NETWORK_DIM=32
NETWORK_ALPHA=16
MIN_SNR_GAMMA=5
```

### 3. **üì∏ Dataset Elena - 35 Images**

**Classification effectu√©e :**

| Angle | Nombre | % | Shot Types |
|-------|--------|---|------------|
| **Front** | ~12 | 34% | closeup (1), medium (11) |
| **3/4** | ~18 | 51% | medium (15), full (3) |
| **Profile** | ~5 | 14% | medium (5) |

**Distribution par location :**
- Rooftop Paris/Balcony : 10 images
- Indoor/Window views : 5 images
- Bedroom/Yoga : 2 images
- Gallery/Passage : 2 images
- Pool/Tropical : 5 images
- Mixed locations : 11 images

**Toutes les URLs Cloudinary :**
```javascript
// Voir app/scripts/prepare-lora-dataset-cloud.mjs
// 35 images avec classification angle/shot compl√®te
```

### 4. **üîë RunPod API Setup**

- **API Key** : `rpa_***` (stored in env vars)
- **Email** : edouard@tiemh.com
- **Spend Limit** : $80
- **Pod existant** : `agreed_coffee_guan` (RTX 4090, EXITED)

**Test connexion** : ‚úÖ OK

---

## üìã Workflow Complet

### √âtape 1 : Pr√©parer le dataset localement ‚úÖ

```bash
cd "/Users/edouardtiem/Cursor Projects/IG-influencer"
node app/scripts/prepare-lora-dataset-cloud.mjs
```

**R√©sultat attendu :**
- Dataset dans `lora-dataset-elena-cloud/10_elena/`
- 35 images 1024x1024
- 35 captions avec trigger word "elena"

### √âtape 2 : Cr√©er/D√©marrer pod RunPod

```bash
# Option A: Utiliser pod existant
node app/scripts/runpod-lora-training.mjs resume

# Option B: Cr√©er nouveau pod
node app/scripts/runpod-lora-training.mjs create
```

**Attendre** : Pod status = RUNNING (check avec `status`)

### √âtape 3 : Upload dataset vers pod

**Depuis machine locale :**
```bash
# R√©cup√©rer SSH command depuis RunPod console
# Format: ssh root@<POD_IP> -p <PORT>

# Upload dataset
scp -P <PORT> -r lora-dataset-elena-cloud/* root@<POD_IP>:/workspace/dataset/
```

### √âtape 4 : Upload script training

```bash
scp -P <PORT> runpod-training-script.sh root@<POD_IP>:/workspace/
```

### √âtape 5 : SSH et lancer training

```bash
ssh root@<POD_IP> -p <PORT>
cd /workspace
chmod +x runpod-training-script.sh
./runpod-training-script.sh
```

**Temps estim√©** : 25-40 minutes sur RTX 4090

### √âtape 6 : Download LoRA final

```bash
# Depuis machine locale
scp -P <PORT> root@<POD_IP>:/workspace/output/elena_v3_cloud.safetensors ~/ComfyUI/models/loras/
```

### √âtape 7 : Stop pod (√©conomiser)

```bash
node app/scripts/runpod-lora-training.mjs stop <POD_ID>
```

---

## üí∞ Co√ªt Estim√©

- **GPU** : RTX 4090 (~$0.44/hr)
- **Temps training** : 30-40 min
- **Total** : ~$0.30-0.40

---

## üìä Comparaison Local vs Cloud

| Aspect | Local (Mac M3) | Cloud (RunPod RTX 4090) |
|--------|----------------|-------------------------|
| **GPU** | M3 Pro 18GB | RTX 4090 24GB |
| **Rank** | 8 (limit√©) | 32 (optimal) |
| **Steps** | 100 | 2100 |
| **R√©solution** | 512x512 | 1024x1024 |
| **Text Encoder** | ‚ùå Non | ‚úÖ Oui |
| **Images** | 10 | 35 |
| **Temps** | ~2h15 | ~30-40min |
| **Co√ªt** | $0 | ~$0.35 |

---

## üéØ R√©sultats Attendus

**Am√©lioration visage :**
- Local : ~10-15% similarit√©
- Cloud attendu : **60-80%** similarit√©

**Raisons :**
- 3.5√ó plus d'images (35 vs 10)
- Rank 4√ó plus √©lev√© (32 vs 8)
- Text Encoder training activ√©
- R√©solution 2√ó plus haute (1024 vs 512)
- 21√ó plus de steps (2100 vs 100)

---

## üìÅ Fichiers Cr√©√©s/Modifi√©s

### Cr√©√©s :
- ‚úÖ `app/scripts/runpod-lora-training.mjs` ‚Äî Gestion pods RunPod
- ‚úÖ `app/scripts/prepare-lora-dataset-cloud.mjs` ‚Äî Pr√©paration dataset
- ‚úÖ `runpod-training-script.sh` ‚Äî Script training optimis√©
- ‚úÖ `docs/sessions/2026-01-20-elena-lora-runpod-setup.md` ‚Äî Ce document

### Modifi√©s :
- ‚úÖ `.env.local` ‚Äî Ajout `RUNPOD_API_KEY`

---

## üöß Prochaines √âtapes

### √Ä faire maintenant :

1. **Lancer pr√©paration dataset**
   ```bash
   node app/scripts/prepare-lora-dataset-cloud.mjs
   ```

2. **V√©rifier dataset cr√©√©**
   ```bash
   ls -la lora-dataset-elena-cloud/10_elena/
   # Devrait voir 35 .jpg + 35 .txt
   ```

3. **D√©marrer pod RunPod**
   ```bash
   node app/scripts/runpod-lora-training.mjs resume
   # Ou cr√©er nouveau: node app/scripts/runpod-lora-training.mjs create
   ```

4. **Suivre workflow √âtape 3-7** ci-dessus

### Apr√®s training :

- [ ] Tester LoRA dans ComfyUI
- [ ] Comparer avec LoRA local (v2)
- [ ] Documenter r√©sultats
- [ ] Mettre √† jour ROADMAP.md

---

## üîó R√©f√©rences

- [RunPod API Docs](https://docs.runpod.io/)
- [Kohya_ss GitHub](https://github.com/bmaltais/kohya_ss)
- [SDXL LoRA Training Guide](https://apatero.com/blog/kohya-ss-lora-training-complete-guide-2025)
- [Reddit r/StableDiffusion LoRA discussions](https://reddit.com/r/StableDiffusion)

---

## üìù Notes Importantes

### Captions Structure

**Format optimis√© :**
```
elena, 24 year old Italian woman, honey brown warm eyes, small beauty mark on right cheekbone, bronde hair with dark roots and golden blonde balayage, long voluminous beach waves, [angle description], sun-kissed Mediterranean skin, photo
```

**Pourquoi cette structure :**
- Trigger word "elena" en premier (keep_tokens=1)
- Features visage toujours pr√©sents
- Pas de termes vagues ("beautiful", "stunning")
- Coh√©rence parfaite entre toutes les captions

### Param√®tres Cl√©s Training

**Text Encoder LR = 5e-5** (plus bas que UNet)
- Permet au mod√®le d'apprendre que "elena" = ce visage sp√©cifique
- Sans √ßa, le trigger word ne fonctionne pas bien

**min_snr_gamma = 5**
- Am√©liore le contraste et la nettet√©
- Particuli√®rement important pour le visage

**Gradient Accumulation = 2**
- Effective batch size = 2
- Training plus stable qu'avec batch_size=1 seul

---

**Status** : ‚úÖ Setup complet, pr√™t pour training  
**Next** : Lancer `prepare-lora-dataset-cloud.mjs` puis suivre workflow
